{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siamese_2_CIFAR_Torch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84LqRFIn4qq5"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvky9vM19LOU"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BztxX0Cd4sR3"
      },
      "source": [
        "Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrUThhKS9Xxv",
        "outputId": "c5a0a6e3-2e57-4d6f-8ad0-20c249f94e68"
      },
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "DEVICE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh4LOmhulnBV"
      },
      "source": [
        "**Custom Dataset:**\r\n",
        "\r\n",
        ">    Input: dataset (Cifar,MNIST,etc.)  \r\n",
        "     return: dataset with pairs of images and label same/different"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsjcnkUU9YSA"
      },
      "source": [
        "class siameseDataset(Dataset):\r\n",
        "    def __init__(self, dataset):\r\n",
        "        # original datasets\r\n",
        "        self.trainset = dataset\r\n",
        "        self.testset = None # later\r\n",
        "        self.len = len(self.trainset)\r\n",
        "       \r\n",
        "        # original trainloaders\r\n",
        "        self.trainloader1 = DataLoader(self.trainset, batch_size=1, shuffle=True)\r\n",
        "        self.trainloader2 = DataLoader(self.trainset, batch_size=1, shuffle=True)\r\n",
        "        self.reset_iterators() \r\n",
        "\r\n",
        "        \r\n",
        "    def __len__(self):\r\n",
        "        # same as the legth of the original dataset\r\n",
        "        return self.len\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "\r\n",
        "        if self.counter == self.len:\r\n",
        "          self.reset_iterators()\r\n",
        "        else:\r\n",
        "          self.counter +=1\r\n",
        "\r\n",
        "        img1, label1 = next(self.iter1)\r\n",
        "        img2, label2 = next(self.iter2)\r\n",
        "\r\n",
        "        # remove the batch dim\r\n",
        "        img1 = img1[0]\r\n",
        "        img2 = img2[0] \r\n",
        "\r\n",
        "        output = torch.stack([img1,img2])\r\n",
        "\r\n",
        "        if label1==label2:\r\n",
        "          return output,1\r\n",
        "        else:\r\n",
        "          return output,0\r\n",
        "\r\n",
        "    def reset_iterators(self):\r\n",
        "        # original iterator\r\n",
        "        self.iter1 = iter(self.trainloader1)\r\n",
        "        self.iter2 = iter(self.trainloader2)\r\n",
        "        self.counter = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oATxyGDblfVP"
      },
      "source": [
        "**Embedding network:**\r\n",
        "\r\n",
        "> From a CIFAR image to 10 dim vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoKFU9QHSeQC"
      },
      "source": [
        "class CNN(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(CNN, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\r\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
        "        \r\n",
        "        # fully connected layers\r\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\r\n",
        "        self.fc2 = nn.Linear(120, 84)\r\n",
        "        self.fc3 = nn.Linear(84, 10)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        \r\n",
        "        # CNNs\r\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\r\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\r\n",
        "        \r\n",
        "        # flatten\r\n",
        "        x = x.view(-1, self.num_flat_features(x))\r\n",
        "        \r\n",
        "        # FCs\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = self.fc3(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "    def num_flat_features(self, x):\r\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\r\n",
        "        num_features = 1\r\n",
        "        for s in size:\r\n",
        "            num_features *= s\r\n",
        "        return num_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QWQePxSli06"
      },
      "source": [
        "**Siamese network:**\r\n",
        "\r\n",
        "> From 2 images to 2 embeddings , while using the same EmbeddingNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCJOnxcna5rU"
      },
      "source": [
        "class SiameseNet(nn.Module):\r\n",
        "    def __init__(self, embedding_net):\r\n",
        "        super(SiameseNet, self).__init__()\r\n",
        "        self.embedding_net = embedding_net\r\n",
        "\r\n",
        "    def forward(self, inputs):\r\n",
        "        \r\n",
        "        # deals with batch\r\n",
        "        x1 = inputs[:,0]\r\n",
        "        x2 = inputs[:,1]\r\n",
        "\r\n",
        "        # predict embeddings \r\n",
        "        output1 = self.embedding_net(x1)\r\n",
        "        output2 = self.embedding_net(x2)\r\n",
        "\r\n",
        "        return output1, output2\r\n",
        "\r\n",
        "    \r\n",
        "    def get_embedding(self, x):\r\n",
        "        return self.embedding_net(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H4Mr_Nz5Wzg"
      },
      "source": [
        "**Dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeTJiY-D5Zu-",
        "outputId": "8d705900-9aff-49b7-f88b-f17387115784"
      },
      "source": [
        "# transformations\r\n",
        "transform = transforms.Compose(\r\n",
        "    [transforms.ToTensor(),\r\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n",
        "\r\n",
        "# CIFAR10 dataset\r\n",
        "cifar = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\r\n",
        "\r\n",
        "# Siamese on CIFAR10 -  dataset $ dataloader \r\n",
        "ds = siameseDataset(cifar)\r\n",
        "dl = DataLoader(ds,batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oYpJ0Yw_PL1"
      },
      "source": [
        "CIFAR's 10 different classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btCh5qfZ9YGY"
      },
      "source": [
        "labels = {}  \r\n",
        "labels[0] = 'airplane'\r\n",
        "labels[1] = 'car'\r\n",
        "labels[2] = 'bird'\r\n",
        "labels[3] = 'cat'\r\n",
        "labels[4] = 'deer'\r\n",
        "labels[5] = 'dog'\r\n",
        "labels[6] = 'frog'\r\n",
        "labels[7] = 'horse'\r\n",
        "labels[8] = 'ship'\r\n",
        "labels[9] = 'truck' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTINrixWlUUt"
      },
      "source": [
        "Sanity check:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-3CKwCGsS5wT",
        "outputId": "a35ff157-e053-4871-d823-ad50585e240b"
      },
      "source": [
        "inputs,label = iter(dl).next()\r\n",
        "CNN()(inputs[0]),CNN()(inputs[1]), SiameseNet(CNN())(inputs)\r\n",
        "'Done!'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Done!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_WCvIdl8F_G"
      },
      "source": [
        "<br><br><br><br><br><br>\r\n",
        "**Contrast Loss**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voZTvl6dhe2N"
      },
      "source": [
        "$L_{contrast} = \\frac{1}{2}(1-Y)D_w^2 + \\frac{1}{2}(Y) {max(0,m-D_w)}^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZlUaq_Ta--8"
      },
      "source": [
        "class ContrastiveLoss(nn.Module):\r\n",
        "    def __init__(self, margin=1.0):\r\n",
        "        super(ContrastiveLoss, self).__init__()\r\n",
        "        self.margin = margin\r\n",
        "        self.eps = 1e-9\r\n",
        "\r\n",
        "    def forward(self, emb1,emb2,label):\r\n",
        "        \r\n",
        "        # print('emb1',emb1.shape)\r\n",
        "        # print('emb2',emb1.shape)\r\n",
        "\r\n",
        "        label = label.float()\r\n",
        "        # print('label',label)\r\n",
        "\r\n",
        "        # euclidean distance\r\n",
        "        distance = (emb1-emb2).pow(2).sum(1).pow(0.5)\r\n",
        "        # print('distance',distance)\r\n",
        "\r\n",
        "        # contrastive loss\r\n",
        "        left = (1 - label) * distance.pow(2)\r\n",
        "        right =    (label) * F.relu(self.margin-distance+self.eps).pow(2) # relu is like max(0,_)\r\n",
        "\r\n",
        "        # print('left',left)\r\n",
        "        # print('right',right)\r\n",
        "\r\n",
        "        loss = 0.5 * (left + right)\r\n",
        "        # print('loss',loss)\r\n",
        "        # print('loss mean',loss.mean())\r\n",
        "        return loss.mean()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYejBxINz6CN",
        "outputId": "6b0268b6-aa08-4d2f-e228-aaf9ef5499e1"
      },
      "source": [
        "ContrastiveLoss()(torch.Tensor(64,10),torch.Tensor(64,10),torch.zeros(1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh-TNhOT8m8m"
      },
      "source": [
        "<br><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kf__cr2mn_Y"
      },
      "source": [
        "**Train function:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m3yVITna_Ji"
      },
      "source": [
        "def train_model(model, trainset, EPOCHS=10, BATCH_SIZE=64, DEVICDE=DEVICE, VERBOSE=False,BASIC_VERBOSE=True):\r\n",
        "\r\n",
        "  if BASIC_VERBOSE:\r\n",
        "    print('Training - began...')\r\n",
        "\r\n",
        "  # define loss function\r\n",
        "  criterion = ContrastiveLoss() \r\n",
        "\r\n",
        "  # define the optimizer\r\n",
        "  optimizer = torch.optim.Adam(model.parameters())\r\n",
        "\r\n",
        "  # dataloader\r\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\r\n",
        "\r\n",
        "  # model to device\r\n",
        "  model = model.to(DEVICE)\r\n",
        "\r\n",
        "  # training loop\r\n",
        "  Loss = []\r\n",
        "  for epoch in range(EPOCHS):  \r\n",
        "\r\n",
        "      running_loss = 0.0\r\n",
        "      for i, data in enumerate(trainloader, 0):\r\n",
        "          # get the inputs\r\n",
        "          inputs, labels = data\r\n",
        "          \r\n",
        "          inputs = inputs.to(DEVICE) \r\n",
        "          labels = labels.to(DEVICE) \r\n",
        "\r\n",
        "          # zero the parameter gradients\r\n",
        "          optimizer.zero_grad()\r\n",
        "\r\n",
        "          # forward + backward + optimize\r\n",
        "          outputs = model(inputs)\r\n",
        "          loss = criterion(*outputs, labels)\r\n",
        "\r\n",
        "          if torch.isnan(loss):\r\n",
        "              print('\\n Got Loss=NaN when i=',i,'\\n Please find returns: loss,outputs,data,model')\r\n",
        "              return loss,outputs,data,model\r\n",
        "\r\n",
        "          loss.backward()\r\n",
        "          optimizer.step()\r\n",
        "\r\n",
        "          running_loss += loss.item() \r\n",
        "          # # print statistics\r\n",
        "          if VERBOSE:\r\n",
        "            if i % 200 == 0:    \r\n",
        "                print('[%d, %5d] loss: %.3f' %\r\n",
        "                      (epoch + 1, i + 1, running_loss / 200))\r\n",
        "                running_loss = 0.0\r\n",
        "\r\n",
        "      Loss.append(running_loss/len(trainloader))\r\n",
        "\r\n",
        "  if BASIC_VERBOSE:\r\n",
        "    print('Training - Done!')\r\n",
        "    print('loss len: ', len(Loss), '\\tfinal loss: ', Loss[-1])\r\n",
        "  return Loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qVj2A-wa_Mi",
        "outputId": "cf132a84-8dc9-4e4e-b667-efa04507c3a3"
      },
      "source": [
        "loss,outputs,data,model = train_model(model=SiameseNet(CNN()),trainset=ds,VERBOSE=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training - began...\n",
            "[1,     1] loss: 0.001\n",
            "[1,   201] loss: 0.045\n",
            "[1,   401] loss: 0.045\n",
            "\n",
            " Got Loss=NaN when i= 536 \n",
            " Please find returns: loss,outputs,data,model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAfSDSQe9GLY"
      },
      "source": [
        "Here is a Contrast Loss from the web:  \r\n",
        "https://github.com/adambielski/siamese-triplet/blob/master/losses.py\r\n",
        "\r\n",
        "But it's also NaN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfnHC0oG4KEJ"
      },
      "source": [
        "class ContrastiveLoss(nn.Module):\r\n",
        "    \"\"\"\r\n",
        "    Contrastive loss\r\n",
        "    Takes embeddings of two samples and a target label == 1 if samples are from the same class and label == 0 otherwise\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, margin=1.0):\r\n",
        "        super(ContrastiveLoss, self).__init__()\r\n",
        "        self.margin = margin\r\n",
        "        self.eps = 1e-9\r\n",
        "\r\n",
        "    def forward(self, output1, output2, target, size_average=True):\r\n",
        "        distances = (output2 - output1).pow(2).sum(1)  # squared distances\r\n",
        "        losses = 0.5 * (target.float() * distances +\r\n",
        "                        (1 + -1 * target).float() * F.relu(self.margin - (distances + self.eps).sqrt()).pow(2))\r\n",
        "        return losses.mean() if size_average else losses.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0R0DJVd4LQd"
      },
      "source": [
        "ContrastiveLoss()(torch.Tensor(64,10),torch.Tensor(64,10),torch.zeros(1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}